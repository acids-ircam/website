1:"$Sreact.fragment"
2:I[7780,["992","static/chunks/992-1842a017ea33c45a.js","586","static/chunks/586-19af1355af70cff6.js","177","static/chunks/app/layout-4cc984cff25efb5d.js"],"ThemeProvider"]
3:I[4803,["992","static/chunks/992-1842a017ea33c45a.js","586","static/chunks/586-19af1355af70cff6.js","177","static/chunks/app/layout-4cc984cff25efb5d.js"],"default"]
4:I[999,["992","static/chunks/992-1842a017ea33c45a.js","586","static/chunks/586-19af1355af70cff6.js","177","static/chunks/app/layout-4cc984cff25efb5d.js"],"default"]
5:I[7555,[],""]
6:I[1295,[],""]
7:I[5078,["992","static/chunks/992-1842a017ea33c45a.js","586","static/chunks/586-19af1355af70cff6.js","177","static/chunks/app/layout-4cc984cff25efb5d.js"],"default"]
8:I[6874,["992","static/chunks/992-1842a017ea33c45a.js","144","static/chunks/app/project/%5Bslug%5D/page-aeb9e8b95bc6a8b4.js"],""]
a:I[3063,["992","static/chunks/992-1842a017ea33c45a.js","144","static/chunks/app/project/%5Bslug%5D/page-aeb9e8b95bc6a8b4.js"],"Image"]
b:I[9665,[],"OutletBoundary"]
e:I[9665,[],"ViewportBoundary"]
10:I[9665,[],"MetadataBoundary"]
12:I[6614,[],""]
:HL["/_next/static/media/806de4d605d3ad01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/a34f9d1faa5f3315-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/fc727f226c737876-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/a30c58ff3d80b1dc.css","style"]
:HL["/_next/static/css/4458994a1e8195d9.css","style"]
9:T5f2,Our work in neural audio synthesis represents a significant advancement in how AI can be applied to sound generation and transformation. We've developed several key technologies that have become standard tools for artists and researchers working at the intersection of AI and audio.

RAVE (Real-time Audio Variational autoEncoder) is our flagship model for high-quality, real-time audio synthesis. Unlike many neural audio models that require significant computational resources, RAVE is optimized for real-time performance on consumer hardware, making it accessible to musicians and sound designers for live performance and studio work.

NN~ brings neural networks directly into the Max/MSP environment, allowing artists to integrate machine learning models into their existing workflows without leaving the tools they're already familiar with. This bridge between traditional computer music environments and cutting-edge AI has enabled new forms of hybrid creativity.

AFTER (Audio Feature Transformer with Encoded RAVE) combines the strengths of transformer architectures with our RAVE model to create a system that can generate longer, more coherent audio sequences while maintaining the real-time performance that makes RAVE so useful in creative contexts.

These technologies share a common philosophy: AI should augment human creativity rather than replace it. We design our tools to be responsive to human input, providing artists with new sonic possibilities while keeping them in control of the creative process.0:{"P":null,"b":"wleDCgw7x3mmFyrKyugCU","p":"","c":["","project","neural-audio-synthesis"],"i":false,"f":[[["",{"children":["project",{"children":[["slug","neural-audio-synthesis","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/a30c58ff3d80b1dc.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/4458994a1e8195d9.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_e8b655 __variable_d65c78 min-h-screen bg-black text-white dark","children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":false,"forcedTheme":"dark","children":[["$","$L3",null,{}],["$","$L4",null,{}],["$","main",null,{"children":["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L7",null,{}]]}]}]}]]}],{"children":["project",["$","$1","c",{"children":[null,["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","neural-audio-synthesis","d"],["$","$1","c",{"children":[null,["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"bg-black min-h-screen pt-24","children":["$","div",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-16","children":[["$","$L8",null,{"href":"/#projects","className":"inline-flex items-center text-gray-400 hover:text-red-500 transition-colors mb-8","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left mr-2 h-4 w-4","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"Back to projects"]}],["$","div",null,{"className":"grid grid-cols-1 lg:grid-cols-2 gap-12 items-start","children":[["$","div",null,{"children":[["$","h1",null,{"className":"text-4xl font-bold text-white mb-4 font-mono","children":"Neural Audio Synthesis"}],["$","p",null,{"className":"text-red-500 font-mono mb-6","children":"Pioneering AI models for sound generation"}],["$","div",null,{"className":"prose prose-invert max-w-none mb-8","children":["$","p",null,{"className":"text-gray-300","children":"$9"}]}],["$","div",null,{"className":"mb-8","children":[["$","h2",null,{"className":"text-xl font-bold text-white mb-2 font-mono","children":"Technologies"}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","PyTorch",{"className":"bg-gray-800 text-gray-300 px-3 py-1 rounded-full text-sm font-mono","children":"PyTorch"}],["$","span","Python",{"className":"bg-gray-800 text-gray-300 px-3 py-1 rounded-full text-sm font-mono","children":"Python"}],["$","span","C++",{"className":"bg-gray-800 text-gray-300 px-3 py-1 rounded-full text-sm font-mono","children":"C++"}],["$","span","CUDA",{"className":"bg-gray-800 text-gray-300 px-3 py-1 rounded-full text-sm font-mono","children":"CUDA"}],["$","span","Audio DSP",{"className":"bg-gray-800 text-gray-300 px-3 py-1 rounded-full text-sm font-mono","children":"Audio DSP"}]]}]]}],["$","div",null,{"className":"mb-8","children":[["$","h2",null,{"className":"text-xl font-bold text-white mb-2 font-mono","children":"Year"}],["$","p",null,{"className":"text-gray-300","children":"2020-Present"}]]}],["$","a",null,{"href":"https://github.com/acids-ircam/RAVE","target":"_blank","rel":"noopener noreferrer","className":"inline-flex items-center bg-red-600 hover:bg-red-700 text-white px-6 py-3 rounded-lg transition-colors font-mono","children":["View Project",["$","svg",null,{"className":"ml-2 h-4 w-4","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"}]}]]}]]}],["$","div",null,{"className":"space-y-6","children":[["$","div",null,{"className":"relative aspect-video overflow-hidden rounded-lg border border-red-900/20","children":["$","$La",null,{"src":"/placeholder.svg?height=600&width=800","alt":"Neural Audio Synthesis","fill":true,"className":"object-cover","sizes":"(max-width: 768px) 100vw, 50vw"}]}],["$","div",null,{"className":"grid grid-cols-3 gap-4","children":[["$","div","0",{"className":"relative aspect-square overflow-hidden rounded-lg border border-red-900/20","children":["$","$La",null,{"src":"/placeholder.svg?height=400&width=600","alt":"Neural Audio Synthesis gallery image 1","fill":true,"className":"object-cover","sizes":"(max-width: 768px) 33vw, 16vw"}]}],["$","div","1",{"className":"relative aspect-square overflow-hidden rounded-lg border border-red-900/20","children":["$","$La",null,{"src":"/placeholder.svg?height=400&width=600","alt":"Neural Audio Synthesis gallery image 2","fill":true,"className":"object-cover","sizes":"(max-width: 768px) 33vw, 16vw"}]}],["$","div","2",{"className":"relative aspect-square overflow-hidden rounded-lg border border-red-900/20","children":["$","$La",null,{"src":"/placeholder.svg?height=400&width=600","alt":"Neural Audio Synthesis gallery image 3","fill":true,"className":"object-cover","sizes":"(max-width: 768px) 33vw, 16vw"}]}]]}]]}]]}]]}]}],"$undefined",null,["$","$Lb",null,{"children":["$Lc","$Ld",null]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","p0spm9SLDOp-DGlgYDWo6",{"children":[["$","$Le",null,{"children":"$Lf"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$L10",null,{"children":"$L11"}]]}],false]],"m":"$undefined","G":["$12","$undefined"],"s":false,"S":true}
f:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
c:null
d:null
11:[["$","title","0",{"children":"ACIDS-IRCAM | Artificial Creative Intelligence and Data Science"}],["$","meta","1",{"name":"description","content":"Exploring musical creativity through AI and deep learning at IRCAM"}],["$","meta","2",{"name":"generator","content":"v0.dev"}]]
